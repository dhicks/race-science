<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>paper</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="paper_files/libs/clipboard/clipboard.min.js"></script>
<script src="paper_files/libs/quarto-html/quarto.js"></script>
<script src="paper_files/libs/quarto-html/popper.min.js"></script>
<script src="paper_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="paper_files/libs/quarto-html/anchor.min.js"></script>
<link href="paper_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="paper_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="paper_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="paper_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="paper_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">



<!-- 
| 
| **One sentence summary:** Bibliometric and text mining analysis indicate that race science discourse appeared in mainstream psychology journals throughout the second half of the twentieth century.  
 -->
<!-- # Introduction {.unnumbered} -->
<p>By the end of the Second World War, a combination of technical developments in anthropology and genetics, along with revelations of Nazi atrocities, had led most members of the scientific community to reject attempts to scientifically justify racial inequalities and colonialism <span class="citation" data-cites="BarkanRetreatScientificRacism1992">[@BarkanRetreatScientificRacism1992]</span>. But eugenic thinking and scientific racism persisted throughout the second half of the twentieth century, and recent work has found that white supremacists continue to attempt to use scientific research to justify racial violence <span class="citation" data-cites="DusterBackdoorEugenics2003 PanofskyHowWhiteNationalists2021 PronczukRacistResearcherExposed2022">[@DusterBackdoorEugenics2003; @PanofskyHowWhiteNationalists2021; @PronczukRacistResearcherExposed2022]</span>.</p>
<p>The aim of the study reported here was to trace race science in the scholarly and parascholarly literature, examining the ways that fringe ideas can present themselves as legitimate scholarly inquiry.</p>
<p>We first propose a distinction between scientific racism, race science, and race science discourse. <em>Scientific racism</em> refers to the social practice of purporting to justify racial inequality and colonialism by appealing to the epistemic authority of science. <em>Race science</em> refers to scientific and/or pseudoscientific research, including research products (journal articles, etc.), that can be utilized for scientific racism. <em>Race science discourse</em> refers to a broader category, any treatment of race science as a legitimate area of scientific research. This includes methodological and empirical critiques of race science. For example, the Flynn effect (the finding that IQ scores have increased over time) poses a serious empirical challenge to hereditarian claims of racial differences in intelligence. But technical debates over the extent and causes of the Flynn effect likely create the impression among the general public of ordinary scientific disagreement. In this way technical critiques of race science based on the Flynn effect could potentially legitimize race science. So empirical research supporting the Flynn effect is usually not itself race science, but can still be race science discourse.</p>
<p>These distinction allow us to bracket the intentions and mindset of the researchers involved in any particular piece of research or debate. For the purposes of the current study, it is not important whether, for instance, Arthur Jensen is or is not correctly labelled a scientific racist <span class="citation" data-cites="JacksonJr.ArthurJensenEvolutionary2022">[@JacksonJr.ArthurJensenEvolutionary2022]</span>. But it is important that much of Jensen’s research was useful and indeed utilized to purportedly justify racial inequality.</p>
<!-- # Scientific racism, eugenics, and *Brown* {.unnumbered} -->
<p>Histories of scientific racism in the twentieth century have often emphasized the Pioneer Fund and the parascholarly journal <em>Mankind Quarterly</em> (MQ) <span class="citation" data-cites="BarkanRetreatScientificRacism1992 MehlerFoundationFascismNew1989 WinstonScienceServiceFar1998 TuckerFundingScientificRacism2002 SchafferScientificRacismAgain2007 SainiSuperiorReturnRace2019 WinstonScientificRacismNorth2020 AdamsMisAppropriationBiological2021 SainiDraperMillionsPhilanthropic2022">[ @BarkanRetreatScientificRacism1992; @MehlerFoundationFascismNew1989; @WinstonScienceServiceFar1998; @TuckerFundingScientificRacism2002; @SchafferScientificRacismAgain2007; @SainiSuperiorReturnRace2019; @WinstonScientificRacismNorth2020; @AdamsMisAppropriationBiological2021; @SainiDraperMillionsPhilanthropic2022]</span>. Pioneer was formed in 1937, during the waning years of the eugenics movement in North America <span class="citation" data-cites="BarkanRetreatScientificRacism1992">[@BarkanRetreatScientificRacism1992]</span>, with the aim of “support[ing] academic research and the '[sic]dissemination of information, into the ‘problem of heredity and eugenics’ and ‘the problems of race betterment’” <span class="citation" data-cites="MehlerFoundationFascismNew1989">[@MehlerFoundationFascismNew1989 p.21, quoting Laughlin]</span>. MQ was founded in 1960 by biologist R. Ruggles Gates (1882-1962), psychologist Henry Garrett (1894-1973), and non-academic anthropologist G. Robert Gayre (self-styled as “Gayre of Gayre and Nigg”; 1907-1996). Gates’ professional status had risen and fallen with eugenics and the explicit scientific racism of the 1920s, and by the end of the Second World War he was thoroughly marginalized <span class="citation" data-cites="WinstonScienceServiceFar1998">[@WinstonScienceServiceFar1998]</span>. In contrast, Garrett had been president of the American Psychological Association in 1946 and chair of Psychology at Columbia from 1941 to 1955 <span class="citation" data-cites="WinstonScienceServiceFar1998">[@WinstonScienceServiceFar1998]</span>.</p>
<p>In the landmark case <em>Brown v Board of Education of Topeka</em> (1954), the US Supreme Court banned <em>de jure</em> educational segregation. The Court’s decision relied on expert testimony from psychologists and education researchers; but the segregationists also put forward their own experts, including Henry Garrett <span class="citation" data-cites="WinstonScienceServiceFar1998 JacksonScienceSegregationRace2005 SchafferScientificRacismAgain2007">[@WinstonScienceServiceFar1998; @JacksonScienceSegregationRace2005; @SchafferScientificRacismAgain2007]</span>. As part of this segregationist reaction, MQ was created to provide a favorable venue for race scientists to publish their views, on the grounds that an “equalitarian dogma” created a censorious “taboo” against their research in mainstream publications <span class="citation" data-cites="TuckerFundingScientificRacism2002 JacksonMythicalTabooRace2020">[@TuckerFundingScientificRacism2002; @JacksonMythicalTabooRace2020]</span>.</p>
<p>In light of the scientific racist origins of Pioneer and MQ, and the significant attention MQ has received in recent historiography, we hypothesized that bibliometric and text mining analyses would show race science ideas originating in MQ, and from there being disseminated to mainstream publications. This hypothesis was not supported. Instead, mainstream psychology journals provided a venue for a distinct form of race science, based on intelligence research and originating outside of MQ.</p>
<section id="results" class="level1">
<h1>Results</h1>
<section id="mankind-quarterly-and-pioneer-funded-researchers" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="mankind-quarterly-and-pioneer-funded-researchers"><em>Mankind Quarterly</em> and Pioneer-funded researchers</h2>
<p>We identified 16 researchers who had received funding from Pioneer; 14 of these researchers had profiles in the Web of Science (WoS) author search, allowing us identify 13 WoS-indexed journals that had published 6 or more of these authors. See <a href="#tbl-researchers">Table&nbsp;1</a> and <a href="#fig-wos">Figure&nbsp;1</a>.</p>
<div id="tbl-researchers" class="anchored">
<table class="table">
<caption>Table&nbsp;1: Pioneer-funded researchers. Either identified in <span class="citation" data-cites="MillerPioneerFundBankrolling1994">[@MillerPioneerFundBankrolling1994]</span> or named on an archive copy of Pioneer’s website, along with birth and death dates from Wikipedia, attributed discipline, and WoS author search result counts. Brunetto Chiarelli does not have a Wikipedia page.</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;">Thomas J. Bouchard, Jr.&nbsp;(1937-)</td>
<td style="text-align: right;">psychology</td>
<td style="text-align: right;">184</td>
</tr>
<tr class="even">
<td style="text-align: left;">Brunetto Chiarelli (?-?)</td>
<td style="text-align: right;">anthropology</td>
<td style="text-align: right;">91</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Hans Eysenck (1916-1997)</td>
<td style="text-align: right;">psychology</td>
<td style="text-align: right;">661</td>
</tr>
<tr class="even">
<td style="text-align: left;">Robert A. Gordon (1932-)</td>
<td style="text-align: right;">sociology</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Linda Gottfredson (1947-)</td>
<td style="text-align: right;">psychology</td>
<td style="text-align: right;">71</td>
</tr>
<tr class="even">
<td style="text-align: left;">Garrett Hardin (1915-2003)</td>
<td style="text-align: right;">ecology</td>
<td style="text-align: right;">75</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Joseph M. Horn (1940-)</td>
<td style="text-align: right;">psychology</td>
<td style="text-align: right;">68</td>
</tr>
<tr class="even">
<td style="text-align: left;">Lloyd Humphreys (1913-2003)</td>
<td style="text-align: right;">psychology</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Arthur Jensen (1923-2003)</td>
<td style="text-align: right;">psychology</td>
<td style="text-align: right;">235</td>
</tr>
<tr class="even">
<td style="text-align: left;">Michael Levin (1943-)</td>
<td style="text-align: right;">philosophy</td>
<td style="text-align: right;">96</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Richard Lynn (1930-2023)</td>
<td style="text-align: right;">psychology</td>
<td style="text-align: right;">288</td>
</tr>
<tr class="even">
<td style="text-align: left;">R. Travis Osborne (1913-2013)</td>
<td style="text-align: right;">psychology</td>
<td style="text-align: right;">59</td>
</tr>
<tr class="odd">
<td style="text-align: left;">J. Phillippe Rushton (1943-2012)</td>
<td style="text-align: right;">psychology</td>
<td style="text-align: right;">277</td>
</tr>
<tr class="even">
<td style="text-align: left;">Audrey M. Shuey (1900-1977)</td>
<td style="text-align: right;">psychology</td>
<td style="text-align: right;">10</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Philip A. Vernon (1950-)</td>
<td style="text-align: right;">psychology</td>
<td style="text-align: right;">227</td>
</tr>
<tr class="even">
<td style="text-align: left;">Daniel Vining, Jr.&nbsp;(1944-)</td>
<td style="text-align: right;">demography</td>
<td style="text-align: right;">33</td>
</tr>
</tbody>
</table>
</div>
<div id="fig-wos" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/wos_results.png" style="width:4.76in;height:2.6in" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Journals publishing 6 or more Pioneer-funded researchers, Web of Science author search results.</figcaption>
</figure>
</div>
<p><a href="#fig-wos">Figure&nbsp;1</a> shows that, while MQ is among the “Pioneer-publishing” journals, a number of mainstream journals are more prominent: <em>Personality and Individual Differences</em> (PID), <em>Intelligence</em> (Int), <em>Behavior Genetics</em> (BG), and <em>Psychological Reports</em> (PR). In addition, only psychologist Richard Lynn appears to have published heavily in MQ. Lynn became an assistant editor of MQ in 1979 (vol.&nbsp;XX, Nos. 1 &amp; 2) and is listed as editor-in-chief on MQ’s current website as of 2023-07-21. He has also been president of Pioneer since the death of psychologist J. Phillippe Rushton in 2012 <span class="citation" data-cites="BeirichPioneerFundAssets2013">[@BeirichPioneerFundAssets2013]</span>. By contrast, a number of Pioneer-funded researchers have published in PID, Int, and to a lesser degree BG: Bouchard, Eysenck, Jensen, Rushton, Vernon, and also Lynn.</p>
<p><em>Personality and Individual Differences</em> (PID) was founded in 1980, with Eysenck as editor-in-chief and an editorial board including Jensen and Lynn. In the inaugural editorial, Eysenck identified “studies of the genetic determinants of individual differences in the areas of personality and intelligence” as one of the journal’s eight major areas of interest. Eysenck remained editor-in-chief until his death in 1997. In 2005 the editorial board still included Jensen and Lynn. PID was first published by Pergamon Press, a mainstream academic press, and today is published by Elsevier.</p>
<p><em>Intelligence</em> (Int) was founded in 1977, with psychologist Douglas Detterman as editor-in-chief from the founding until 2016. Lloyd Humphreys was on the editorial board starting from 1977; by 1990 he had been joined by Jensen and Philip Vernon. Richard Lynn joined the editorial board sometime between 1998 and 2002. (Archive copies of the Int editorial board page are not available from the journal’s website from 1999 through 2001.) Int has been criticized for including Lynn and Gerhard Meisenberg — who was editor-in-chief of MQ in 2015-18 — on its editorial board until 2018 <span class="citation" data-cites="SainiSuperiorReturnRace2019">[@SainiSuperiorReturnRace2019]</span>. Int is published by Elsevier.</p>
</section>
<section id="topic-model-analysis-identifies-race-science-discourse" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="topic-model-analysis-identifies-race-science-discourse">Topic model analysis identifies race science discourse</h2>
<p>The fact that Pioneer-funded researchers published heavily in two mainstream psychology journals does not tell us anything about the content of their publications or the claims of their research. We assembled a full-text corpus of articles published in MQ, PID, Int, BG, PR, and Behavior and Brain Sciences (BBS) between 1960-2010 and used topic modeling to identify topics discussing race, intelligence, and both.</p>
<div id="fig-focal" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/focal_topics.png" style="width:4.76in;height:3.57in" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Silge plots <span class="citation" data-cites="SilgeTopicModeling2017">[@SilgeTopicModeling2017]</span> and smoothed time series for three focal topics. Top row: top 15 terms by <span class="math inline">\(\beta\)</span> (term-topic distribution) for each topic. Bottom row: count of articles associated with each topic, by journal and year. Article counts use a threshold approach, with <span class="math inline">\(\gamma\)</span> (topic-document distribution) greater than 0.5. Thin lines give annual values, thick lines give 5-year running averages. Because <em>Behavior Genetics</em> and <em>Behavioral and Brain Sciences</em> are not prominent in any panel, neither is given a direct label.</figcaption>
</figure>
</div>
<p><a href="#fig-focal">Figure&nbsp;2</a> and this discussion focuses on three topics identified in one of the 24 fitted topic models; see figures <a href="#fig-gamma-lg">Figure&nbsp;5</a>, <a href="#fig-gamma-md">Figure&nbsp;6</a>, <a href="#fig-gamma-sm">Figure&nbsp;7</a> and supplemental visualizations S2-S4 for all topics from all models and S5-S7 for selected topics from all models. In the focal model, topic 07 is strongly associated with MQ: MQ published dozens of articles in this topic each year, and no other journal ever published more than a handful. The “Silge plot,” showing the top 15 terms in the topic <span class="citation" data-cites="SilgeTopicModeling2017">[@SilgeTopicModeling2017]</span>, contains racial terms (<code>races</code>, <code>whites</code>, <code>negroes</code> and potentially <code>europe</code>, <code>africa</code>, <code>india</code>, and <code>japan</code>) as well as <code>book</code>, likely reflecting the fact that MQ published a number of book reviews, while the psychology journals either did not or these were not available for the corpus.</p>
<p>Topic 22 is strongly associated with Int and PID in the same way that 07 is associated with MQ. The Silge plot does contain <code>jensen</code>, as well as a reference to Raymond Cattell, who played a major role in the development of factor analysis and intelligence testing but also advocated for eugenics, fascism, and Nazi race science <span class="citation" data-cites="MehlerBeyondismRaymondCattell1997">[@MehlerBeyondismRaymondCattell1997]</span>. However, the other authors named in this topic — John Horn and Peter Bentler — do not appear to have contributed to scientific racism. Instead this topic appears to identify “mainstream” (non-race science) intelligence research, especially factor analysis and the debate over whether intelligence is unidimensional or multidimensional. (Three other topics only associated with mainstream intelligence journals and terms were also identified by this topic model.) This topic indicates that the model is not simply lumping race science research together with other intelligence research.</p>
<p>The Silge plot for topic 24, by contrast, suggests a distinct race science discourse topic, with multiple racial terms (<code>whites</code>, <code>blacks</code>, <code>racial_differences</code>, <code>races</code>, <code>race_differences</code>) and the names of three prominent Pioneer-funded researchers, <code>jensen</code>, <code>lynn</code>, and <code>rushton</code>. Independent qualitative coding of the top 121 papers in this topic (those with <span class="math inline">\(\gamma &gt; 0.97\)</span>) confirmed this interpretation of the topic, with 108 (89%) coded as race science discourse by both authors (Cohen’s <span class="math inline">\(\kappa = 0.86\)</span>).</p>
<p>In almost all years, most papers in topic 24 were published in mainstream journals rather than MQ. Jensen’s “How Much Can We Boost IQ and Scholastic Achievement?” <span class="citation" data-cites="JensenHowMuchCan1969">[@JensenHowMuchCan1969]</span> was published in 1969 in <em>Harvard Educational Review</em> (not included in this study), and the time series indicates that, in the early 1970s, there was an increase in articles in topic 24 in both PR and MQ (the only two journals in our corpus that were active at the time). MQ shows another sharp increase in the late 1980s; using content analysis, Adams and Pilloud found that psychology was the dominant discipline in MQ in the period 1992-2018 <span class="citation" data-cites="AdamsMisAppropriationBiological2021">[@AdamsMisAppropriationBiological2021]</span>. PID published multiple papers in topic 24 almost immediately after it was founded, with Int showing a more gradual increase between the mid-1970s and mid-1990s.</p>
</section>
<section id="race-science-behavior-genetics-and-psychology" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="race-science-behavior-genetics-and-psychology">Race science, behavior genetics, and psychology</h2>
<p>It’s notable that BG published very few articles in any race-and-intelligence topic identified by any of the 24 topic models. Among both academics and the general public, the field of behavior genetics is strongly associated with race science, and specifically race-and-intelligence research. Panofsky <span class="citation" data-cites="PanofskyMisbehavingScienceControversy2014">[@PanofskyMisbehavingScienceControversy2014]</span> argues that, prior to Jensen’s 1969 paper, behavior genetics emphasized the study of non-human animals and intentionally avoided associations with eugenics and public controversy more generally. In response to Jensen, critics such as Lewontin offered broad critiques of behavior genetics as such, and behavior geneticists in turn adopted a radical conception of academic freedom (without any sense of responsibility for the social implications of academic research) and a siege or wartime mentality, as illustrated by Sandra Scarr’s 1986 presidential address to the Behavior Genetics Association (BGA) <span class="citation" data-cites="ScarrThreeCheersBehavior1987">[@ScarrThreeCheersBehavior1987]</span>. Scarr’s address coincided with the period between 1970-1990 when BG published articles in topic 24 (including Scarr’s address itself).</p>
<p>However, the topic model analysis suggests that, by the 1990s, behavior genetics may have distanced itself somewhat from race science, albeit without directly repudiating it. This interpretation was supported by a supplemental analysis that focused on BG specifically (SM section 1.5). In addition, the 1995 BGA presidential address by Glayde Whitney — in which he criticized the “Marxist-Lysenkoist denial of genetics” and proposed that differences in murder rates between countries and cities were caused by racial genetic differences in intelligence, empathy, aggression, and impulsivity — was published in MQ rather than BG. As a subdiscipline of psychology, behavior genetics may have been prominent in promoting race science in the past, but appears to have been less receptive to such ideas in more recent history.</p>
<p>Instead, our results suggest that other subdisciplines of psychology have provided the primary venue for mainstreaming race science. Over the past few decades, many professional organizations in genetics and anthropology have made formal statements rejecting race as a biologically meaningful concept <span class="citation" data-cites="anthropology1996aapa american2018ashg board1998aaa committee2020asa FuentesAAPAStatementRace2019 nhgri2023 rotimi2022ashg wynshawboris2020ashg">[@anthropology1996aapa; @american2018ashg; @board1998aaa; @committee2020asa; @FuentesAAPAStatementRace2019; @nhgri2023; @rotimi2022ashg; @wynshawboris2020ashg]</span>, undermining the core assumption of race science. The American Psychological Association (APA) — whose members are predominantly clinical psychologists — and the Federation of Associations in Behavioral &amp; Brain Sciences (FABBS) — an organization whose purpose is to provide policy recommendations — have openly rejected race as biologically meaningful <span class="citation" data-cites="american2021apology baron2022fabbs">[@american2021apology; @baron2022fabbs]</span>. But research-focused psychological organizations like the Association for Psychological Science (APS) and Psychonomic Society (PS) stop short of rejecting race as biologically meaningful when they denounce racism <span class="citation" data-cites="aps2021statement board2020psychonomic">[@aps2021statement; @board2020psychonomic]</span>. Psychology as a discipline maintains space for several mythological race science narratives, such as allegations of a taboo against race and intelligence research <span class="citation" data-cites="jackson2021mythical">[@jackson2021mythical]</span>, claims that scientists engaging in or calling for any kind of anti-racism in the field is an ideological corruption of dispassionate and value-neutral science <span class="citation" data-cites="roberts_2022">[@roberts_2022]</span>, or arguments that holding race science to the same evidentiary standards as other psychological research is a violation of academic freedom <span class="citation" data-cites="herbert2023academic">[@herbert2023academic]</span>. And historically several race scientists have secured important gatekeeping positions within the scientific community, such as on the editorial boards of Int and PID.</p>
</section>
</section>
<section id="discussion" class="level1 unnumbered">
<h1 class="unnumbered">Discussion</h1>
<p>Using bibliometric and text-mining methods, this study finds that Pioneer-funded researchers published heavily in certain mainstream psychology journals, much more than in <em>Mankind Quarterly</em>; and that a distinct topic of race science discourse, centered on race and intelligence, can be identified in these same mainstream journals across the period 1960-2010. These findings indicate that <em>Mankind Quarterly</em> (MQ) was less important as venue for late 20th century race science than mainstream psychology journals, especially <em>Intelligence</em> (Int) and <em>Personality and Individual Differences</em> (PID). Indeed, until the 1990s, MQ published a very different kind of race science from the race-and-intelligence research published in Int and PID. During this same period of time, race scientists served in prominent and influential positions in behavior genetics and psychology, including as society presidents and members of journal editorial boards. In some cases, some race scientists simultaneously maintained active connections to both the mainstream scientific community and white supremacist organizations <span class="citation" data-cites="WinstonScientificRacismNorth2020 JacksonJr.ArthurJensenEvolutionary2022 SlobodianUnequalMindHow2023">[@WinstonScientificRacismNorth2020; @JacksonJr.ArthurJensenEvolutionary2022; @SlobodianUnequalMindHow2023]</span>. Except for the APA, we are not aware of other major organizations for scientific research in psychology that have issued apologies for the historical contributions of their field to scientific racism.</p>
<p>We are not identifying any particular scientist as a racist, scientific racist, or race scientist based on the topic model results alone. Such claims require an analysis of documentary evidence that goes beyond the scope of the current study <span class="citation" data-cites="JacksonJr.ArthurJensenEvolutionary2022">[@JacksonJr.ArthurJensenEvolutionary2022]</span>. We do assume that our readers, like us, regard white supremacy and scientific racism as morally odious and beyond the scope of reasonable debate <span class="citation" data-cites="SchroederLimitsDemocratizingScience2022">[@SchroederLimitsDemocratizingScience2022]</span>. However, scientific research can be appropriated to promote scientific racism — and thus count as race science — even when this is contrary to the intentions of the original researchers themselves <span class="citation" data-cites="TaberyWhyStudyingGenetics2015 GillbornSoftlySoftlyGenetics2016 CarlsonQuantifyingContextualizingImpact2020 HennWhyDNANo2021">[@TaberyWhyStudyingGenetics2015; @GillbornSoftlySoftlyGenetics2016; @CarlsonQuantifyingContextualizingImpact2020; @HennWhyDNANo2021]</span>. Panofsky et al.&nbsp;show how the term “human biodiversity,” originally developed for anti-racist purposes by biological anthropologist Jonathan Marks, has been inverted by white supremacists and is now a dogwhistle for biological racial hierarchy <span class="citation" data-cites="PanofskyHowWhiteNationalists2021">[@PanofskyHowWhiteNationalists2021]</span>.</p>
<p>Research on the genetics of intelligence has been socially harmful, not just in the somewhat abstract sense of promoting racial stigma, but in the concrete sense of being used to rationalize mass shootings and other acts of racial violence <span class="citation" data-cites="PronczukRacistResearcherExposed2022 MeyerWrestlingSocialBehavioral2023">[@PronczukRacistResearcherExposed2022; @MeyerWrestlingSocialBehavioral2023]</span>. While scientists do not fully control the downstream social effects of their research, like other citizens scientists are responsible for mitigating reasonably foreseeable harms that result from their actions <span class="citation" data-cites="BlockIQHeritabilityInequality1974a DouglasSciencePolicyValuefree2009 KitcherArgumentFreeInquiry1997 KouranyShouldKnowledgeBe2016">[@BlockIQHeritabilityInequality1974a; @DouglasSciencePolicyValuefree2009; @KitcherArgumentFreeInquiry1997; @KouranyShouldKnowledgeBe2016]</span>. These actions include not only individual decisions to research this topic or that, but also collective decisions about who is awarded positions of power or influence. Given the way research on intelligence and behavior genetics has been used historically, these fields may be especially susceptible to appropriation by scientific racists. This only strengthens the obligations of researchers in these areas to prevent their research from causing harm <span class="citation" data-cites="CarlsonQuantifyingContextualizingImpact2020 OgbunugaforDNABasketballBirthday2022">[@CarlsonQuantifyingContextualizingImpact2020; @OgbunugaforDNABasketballBirthday2022]</span>.</p>
<p>How should psychologists exercise these responsibilities? We believe restorative or reparative justice provides a useful model <span class="citation" data-cites="WenzelRetributiveRestorativeJustice2008 WormerRestorativeJustice2013">[@WenzelRetributiveRestorativeJustice2008; @WormerRestorativeJustice2013]</span>. Unlike retributive justice (used by almost all criminal justice systems today), the aim of restorative justice is to repair the damaged relationships between victims and perpetrators of injustice. Typically, restorative justice requires perpetrators to not only acknowledge their actions and the harms that these actions had on victims, but also to work with victims to identify concrete actions that perpetrators can take to redress or mitigate these harms. From this perspective, explicit apologies for contributions to scientific racism are essential as a first step <span class="citation" data-cites="FuentesAAPAStatementRace2019 american2021apology JacksonFacingOurHistory2023">[@FuentesAAPAStatementRace2019; @american2021apology; @JacksonFacingOurHistory2023]</span>, but not fully sufficient on their own.</p>

<!-- 
\clearpage
\pagenumbering{arabic}
\renewcommand*{\thepage}{\thesection.\arabic{page}}
\appendix
\renewcommand{\thesection}{S\arabic{section}}
\renewcommand\thefigure{\thesection.\arabic{figure}}    
\setcounter{figure}{0} 
\renewcommand\thetable{\thesection.\arabic{table}}    
\setcounter{table}{0}


\clearpage

# Supplemental Materials {.unnumbered}

| 
| S1. Materials and methods
| Figures S2-S7
| Data S8, S9

\clearpage
 -->
</section>
<section id="materials-and-methods" class="level1">
<h1>Materials and methods</h1>
<section id="corpus-assembly" class="level2">
<h2 class="anchored" data-anchor-id="corpus-assembly">Corpus assembly</h2>
<div id="fig-corpus" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/dataset.png" class="img-fluid figure-img" style="width:120.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Corpus assembly.</figcaption>
</figure>
</div>
<p>Corpus assembly is summarized in <a href="#fig-corpus">Figure&nbsp;3</a>. The corpus was assembled in two parts, one for <em>Mankind Quarterly</em> and the other for mainstream journals.</p>
<section id="mankind-quarterly" class="level3">
<h3 class="anchored" data-anchor-id="mankind-quarterly">Mankind Quarterly</h3>
<p>An electronic archive of <em>Mankind Quarterly</em>, from the first issue in 1969 through 2004, is available for free on the open web at the white nationalist website <em>The Unz Review</em>. The Python package Beautiful Soup (<a href="https://www.crummy.com/software/BeautifulSoup/" class="uri">https://www.crummy.com/software/BeautifulSoup/</a>, version not recorded) was used to retrieve every PDF available in this archive. After identifying some gaps (missing issues) in the archive from <em>The Unz Review</em>, we manually retrieved PDFs for further articles using ProQuest. Text was extracted using the R package <code>pdftools</code> <span class="citation" data-cites="OomsPdftoolsTextExtraction2023">[@OomsPdftoolsTextExtraction2023 version 3.0.1]</span>. This stage of corpus assembly was conducted in Fall 2021 with the assistance of Anthony Sainez.</p>
</section>
<section id="mainstream-journals" class="level3">
<h3 class="anchored" data-anchor-id="mainstream-journals">Mainstream journals</h3>
<p>To identify suitable mainstream journals for inclusion in the corpus, we first identified academic researchers who had been funded by the Pioneer Fund. Pioneer is an American non-profit organization founded in 1937 to fund eugenics research and propaganda <span class="citation" data-cites="TuckerFundingScientificRacism2002">[@TuckerFundingScientificRacism2002]</span>. After the <em>Brown v. Board of Education</em> ruling in 1954, Pioneer funded various segregationist efforts across the United States, including lectures on eugenics by Stanford physicist William Shockley <span class="citation" data-cites="JacksonScienceSegregationRace2005">[@JacksonScienceSegregationRace2005]</span>. We reviewed a critical profile of Pioneer <span class="citation" data-cites="MillerPioneerFundBankrolling1994">[@MillerPioneerFundBankrolling1994]</span> as well as an archived page from the organization’s own web site (<a href="https://web.archive.org/web/20130103005545/http://www.pioneerfund.org/Grantees.html" class="uri">https://web.archive.org/web/20130103005545/http://www.pioneerfund.org/Grantees.html</a>), which together listed 16 researchers who had received Pioneer funds.</p>
<p>We then used the author search tool in Clarivate’s Web of Science platform (<a href="https://www.webofscience.com/wos/author/search" class="uri">https://www.webofscience.com/wos/author/search</a>), retrieving publication lists for 14 researchers. These searches were conducted between 2021-09-24 and 2021-10-05 by DJH. After parsing these results, we counted how many of the 14 researchers had published in each journal. Thirteen journals had published 6 or more of the 14 Pioneer-funded researchers. We excluded <em>Mankind Quarterly</em> (as already included) as well as <em>Science</em> and <em>Nature</em> (as too general) from further consideration in this side of the corpus. Three journals published by the American Psychological Association (APA; <em>American Psychologist</em>, <em>Contemporary Psychology</em>, and <em>Journal of Educational Psychology</em>) had to be excluded due to confusion over who could give us permission to use the archives for a text mining project, with both APA and ProQuest asserting that we needed to get permission from the other entity. <em>European Journal of Personality</em>, published by SAGE, also had to be excluded because our institutional access only went back to 1999.</p>
<p>The remaining 5 journals are all published by major academic publishers — Elsevier, Springer, or Cambridge University Press — and each item in the entire run of each journal has been assigned a DOI (digital object identifier) for archival purposes. We used the Crossref API and <code>rcrossref</code> R interface to this API <span class="citation" data-cites="ChamberlainRcrossrefClientVarious2019">[@ChamberlainRcrossrefClientVarious2019 version 1.1.0.99]</span> to retrieve metadata for each item published from 1960-2010 in each of these journals. These metadata included item-level license information — confirming that the text of each item could be used for text mining projects — and a URL to an electronic version of the item. These URLs were used to retrieve a XML or PDF version of each item, except for <em>Personality and Individual Differences</em>. This journal has published a relatively large number of non-article documents, such as book reviews and commentaries, that are not available at the URL included in the Crossref metadata. (This is unfortunate, as it was not difficult to find highly relevant documents that we could not automatically retrieve and therefore had to be excluded from our corpus. One set of examples is an exchange between Rushton and Flynn on the Flynn effect <span class="citation" data-cites="FlynnEvidenceRushtonGenetic1998 RushtonSecularGainsIQ1998 FlynnReplyRushtonGang1998">[@FlynnEvidenceRushtonGenetic1998; @RushtonSecularGainsIQ1998; @FlynnReplyRushtonGang1998]</span>.) Instead we used Elsevier’s ScienceDirect API (<a href="https://dev.elsevier.com/" class="uri">https://dev.elsevier.com/</a>) to independently search and retrieve all available items from <em>Personality and Individual Differences</em>. This stage of corpus assembly was conducted between 2021-11 and 2022-05.</p>
<p><em>Behavioral and Brain Sciences</em> typically uses a target article + commentary format; in some cases there are dozens of commentaries for a single article. In the Crossref DOI metadata, each target article and individual commentary is given its own DOI, with no distinction between contribution types or metadata links between a commentary and the corresponding target article. But text is only available in aggregate PDFs that bundle together the target article and all of the commentaries. In somes cases this results in PDFs that are hundreds of pages long and might be linked from the Crossref metadata 30+ times. In addition, the retrieved PDFs are not perfectly identical, because Cambridge UP’s servers add a timestamped watermark to each page when the PDF is requested. We attempted to contact Cambridge for assistance but did not receive a response. We ultimately used a series of ad hoc measures to mitigate text duplication. Approximately 100,000 documents that were 1-2 pages long were excluded before PDF retrieval. After PDF retrieval and text extraction, the timestamped watermarks were removed using a regular expression and the text was hashed using SHA 256. Hashes were used to construct groups of duplicate documents, and a single document (whichever one happened to be first in the dataframe) was chosen from each hash group for inclusion in the corpus. It is plausible that some duplicates made it through this process: where the watermark overlapped with the text, the regular expression likely would have been unable to identify and remove the watermark (a false negative result), and this small difference in the watermarks (not the text) would produce different hashes.</p>
<p>After XML/PDF versions were retrieved, text was extracted using either the <code>xml2</code> package <span class="citation" data-cites="WickhamXml2ParseXML2023">[@WickhamXml2ParseXML2023]</span> or <code>pdftools</code>. <a href="#fig-counts">Figure&nbsp;4</a> and <a href="#tbl-counts">Table&nbsp;2</a> show the number of fulltext documents included in the corpus. All together, the corpus includes 34,896 documents from 6 journals.</p>
<div id="fig-counts" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/02_count.png" style="width:4.76in;height:3.6in" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Count of documents in the corpus, by journal and year.</figcaption>
</figure>
</div>
<div id="tbl-counts" class="anchored">
<table class="table">
<caption>Table&nbsp;2: Document counts, by journal, and years included in the corpus.</caption>
<thead>
<tr class="header">
<th style="text-align: left;">journal</th>
<th style="text-align: right;">n</th>
<th style="text-align: right;">start</th>
<th style="text-align: right;">end</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Behavior Genetics</td>
<td style="text-align: right;">2268</td>
<td style="text-align: right;">1970</td>
<td style="text-align: right;">2010</td>
</tr>
<tr class="even">
<td style="text-align: left;">Intelligence</td>
<td style="text-align: right;">1237</td>
<td style="text-align: right;">1977</td>
<td style="text-align: right;">2010</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Mankind Quarterly</td>
<td style="text-align: right;">1821</td>
<td style="text-align: right;">1960</td>
<td style="text-align: right;">2004</td>
</tr>
<tr class="even">
<td style="text-align: left;">Personality and Individual Differences</td>
<td style="text-align: right;">7274</td>
<td style="text-align: right;">1980</td>
<td style="text-align: right;">2010</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Psychological Reports</td>
<td style="text-align: right;">21398</td>
<td style="text-align: right;">1960</td>
<td style="text-align: right;">2010</td>
</tr>
<tr class="even">
<td style="text-align: left;">Behavioral and Brain Sciences</td>
<td style="text-align: right;">898</td>
<td style="text-align: right;">1978</td>
<td style="text-align: right;">2010</td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="text-preparation" class="level2">
<h2 class="anchored" data-anchor-id="text-preparation">Text preparation</h2>
<p>After document retrieval and text extraction, we pre-processed the text using the <code>spaCy</code> NLP (natural language processing) Python library <span class="citation" data-cites="SpaCyIndustrialstrengthNatural2018">[@SpaCyIndustrialstrengthNatural2018 version 1.9.0]</span> and the R API <code>spacyr</code> <span class="citation" data-cites="BenoitSpacyrWrapperSpaCy2020">[@BenoitSpacyrWrapperSpaCy2020 version 1.2.1]</span>. Specifically, we applied regular expressions to remove header/footer copyright notices and hyphenation, used spaCy to annotate and extract noun phrases (eg, “the intelligence test items”), and then cleaned and standardized these phrases (eg, removing the/an/a, coverting all text to lowercase, and replacing all whitespace with underscores: “intelligence_test_items”). We then counted the occurrence of each noun phrase in the document. The aggregated “document-term matrix” was stored in Parquet format <span class="citation" data-cites="VohraApacheParquet2016">[@VohraApacheParquet2016]</span> for performance reasons, and written and read using the <code>arrow</code> package for R <span class="citation" data-cites="RichardsonArrowIntegrationApache2023">[@RichardsonArrowIntegrationApache2023 version 7.0.0]</span>.</p>
<p>NLP-extracted noun phrases offer a number of advantages over the more traditional unigram (“single word”) terms. First, noun phrase extraction removes many standard stopwords (articles, common verbs, numbers) without relying on a fixed, a priori stopword list. Phrases can be more informative than single terms, for example, distinguishing “intelligence test” from “hypothesis test.” While simple n-gram extraction will include numerous phrases that are not especially meaningful. Consider the sentence “Since our first analyses of feeding patterns in rats, we had been using a criterion of 40 minutes (Le Magnen &amp; Tallon 1963; 1966)”<span class="citation" data-cites="SclafaniCorrelationCausationStudy1981">[@SclafaniCorrelationCausationStudy1981]</span>. Bigrams such as “since our” and “criterion 40” will likely be discarded in vocabulary selection, but significantly increase the computational cost of vocabulary selection. Noun phrase extraction is therefore more efficient.</p>
<p>After noun phrase extraction, the corpus comprised 43,162,055 total tokens of 6,320,783 distinct phrases.</p>
<section id="data-and-code-availability" class="level3">
<h3 class="anchored" data-anchor-id="data-and-code-availability">Data and code availability</h3>
<p>Document metadata retrieved from Crossref does not appear to be covered by any copyright or other intellectual property restrictions. However, due to copyright restrictions, we are unable to make document fulltext or Web of Science search results publicly available. Code for the corpus assembly and text preparation steps described above is available by request.</p>
<p>The public analysis repository, <a href="https://github.com/dhicks/race-science" class="uri">https://github.com/dhicks/race-science</a> <em>[DOI]</em>, includes document metadata and documentwise counts of NLP-extracted noun phrases (“document-term matrices”), along with code to reproduce the analysis of the following sections.</p>
</section>
</section>
<section id="vocabulary-selection" class="level2">
<h2 class="anchored" data-anchor-id="vocabulary-selection">Vocabulary selection</h2>
<p>We took an information-theoretic approach to vocabulary selection<span class="citation" data-cites="HicksProductivityInterdisciplinaryImpacts2021">[@HicksProductivityInterdisciplinaryImpacts2021]</span>. Consider a game in which I draw a document from the corpus, then a single token from that document. I tell you the term, and you have to guess which document I picked. Intuitively, highly informative terms (in this project, noun phrase types) are distinctive, allowing you to dramatically narrow down the list of potential documents. This “informativeness” of a term can be quantified as the KL (Kullback-Leibler) divergence from a “baseline” uniform distribution across documents to the distribution conditional on the term, which we abbreviate as <span class="math inline">\(\Delta H\)</span>. Because the most informative terms tend to be typos and OCR errors — these are unique to a single document — we multiply the KL divergence by the logarithm of the total number of occurrences of the term across the entire corpus. We refer to the resulting measure as <span class="math inline">\(log(n) \Delta H\)</span> or <code>ndH</code>.</p>
<p>In the current project, we found that this <code>ndH</code> approach heavily favored recurrent noun phrases in the longest documents. Many of the documents published in <em>Psychological Reports</em> are extremely short, 1-2 page brief notices of a single study; while many of the documents published in <em>Brain and Behavioral Sciences</em> are book-length collections that include a long review article and sometimes dozens of commentaries. Very generic noun phrases that happen to appear in BBS can occur orders of magnitude more often than highly distinctive phrases in PS, and so the <span class="math inline">\(log(n)\)</span> factor overwhelms the <span class="math inline">\(\Delta H\)</span> factor.</p>
<p>To address this, we used a different baseline distribution of documents, namely, one in which document probability is proportional to length. This makes phrases from short documents much more “surprising” (much less likely to occur according to the baseline), and hence substantially increases their informativeness. This was more effective at identifying useful phrases from across the corpus.</p>
<p>A common rule of thumb in topic modeling is that the vocabulary should have about 10 times as many distinct terms as the number of documents in the corpus. However, we had some concerns with computational demands here: the resulting document-term matrix would have roughly <span class="math inline">\(10 \times 33,000^2\)</span> or 10.9 billion entries; with 10% density this would require on the order of 4 GB of memory just for a single copy of the matrix; and most of the analysis was to be conducted on the authors’ laptops. We therefore chose to work with three smaller vocabularies, <span class="math inline">\(5 \times\)</span>, <span class="math inline">\(1 \times\)</span> and <span class="math inline">\(\frac{1}{5} \times\)</span> the number of documents. We refer to these as the “large” (174,480 distinct phrases), “medium” (34,896) and “small” (6,979) vocabulary, respectively. We compare findings across vocabularies as a robustness check.</p>
</section>
<section id="topic-modeling" class="level2">
<h2 class="anchored" data-anchor-id="topic-modeling">Topic modeling</h2>
<p>To fit topic models, we followed the approach proposed by Rohe and Zeng <span class="citation" data-cites="RoheVintageFactorAnalysis2020">[@RoheVintageFactorAnalysis2020]</span>, which uses varimax-rotated partial principal components instead of the variational inference methods used by standard topic model packages such as <code>stm</code> <span class="citation" data-cites="RobertsStmPackageStructural2019">[@RobertsStmPackageStructural2019]</span>. This novel approach was implemented in the R package <code>tmfast</code> <span class="citation" data-cites="HicksTmfastFitsTopic2023">[@HicksTmfastFitsTopic2023]</span>. We conducted a simulation study of <code>tmfast</code>, which found that it was significantly faster and only slightly less accurate at reconstructing known word-topic and topic-document distributions, compared to <code>stm</code> <span class="citation" data-cites="HicksTmfastFitsTopic2023">[@HicksTmfastFitsTopic2023]</span>.</p>
<p>Topic models were fit for all three vocabularies (large, medium, and small) with <span class="math inline">\(k = 5, 10, 20, ..., 70\)</span> (number of topics), resulting in a total of <span class="math inline">\(24 = 3 \times 8\)</span> models.</p>
<p>Following the approach of <span class="citation" data-cites="HicksProductivityInterdisciplinaryImpacts2021">[@HicksProductivityInterdisciplinaryImpacts2021]</span>, we did not attempt to identify a unique best fitted model for further analysis. While the manuscript text focuses on the medium vocabulary, <span class="math inline">\(k=40\)</span> model as the “median” among the 24 fitted models, we compare and contrast findings from this model with those from the other models.</p>
<section id="topic-model-interpretation-and-quality-assessment" class="level3">
<h3 class="anchored" data-anchor-id="topic-model-interpretation-and-quality-assessment">Topic model interpretation and quality assessment</h3>
<p>After fitting topic models, our first research question was whether we could identify distinctive “race science discourse” topics. <a href="#fig-gamma-lg">Figure&nbsp;5</a>, <a href="#fig-gamma-md">Figure&nbsp;6</a>, <a href="#fig-gamma-sm">and&nbsp;7</a> show the gamma (topic-document) distributions for each value of <span class="math inline">\(k\)</span> for the three vocabularies. In these figures, each panel corresponds to a single journal-<span class="math inline">\(k\)</span> combination, each row of cells is a single document in that journal, and each column of cells is a single topic in that particular model. Topics correspond within columns of panels, but not within rows; for example, topic 04 for <span class="math inline">\(k=10\)</span> does not necessarily correspond to topic 04 for <span class="math inline">\(k=20\)</span>. Color intensity indicates the value of gamma for that particular topic-document combination.</p>
<div id="fig-gamma-lg" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/05_lg_gamma.png" style="width:6in;height:4.8in" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;5: Fitted topic models: Gamma (topic-document) distributions, large vocabulary.</figcaption>
</figure>
</div>
<div id="fig-gamma-md" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/05_md_gamma.png" style="width:6in;height:4.8in" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;6: Fitted topic models: Gamma (topic-document) distributions, medium vocabulary.</figcaption>
</figure>
</div>
<div id="fig-gamma-sm" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/05_sm_gamma.png" style="width:6in;height:4.8in" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;7: Fitted topic models: Gamma (topic-document) distributions, small vocabulary.</figcaption>
</figure>
</div>
<p>For <span class="math inline">\(k=5, 10\)</span> the distributions are quite noisy, difficult to interpret, and generally don’t form very strong visual clusters. As <span class="math inline">\(k\)</span> increases from 20 through 40, coherent bands start to appear for journal-distinctive topics in MQ, BG, Int and, to a lesser degree, PID. Note that the distinctive topics for MQ and Int do not obviously coincide. Above about <span class="math inline">\(k=50\)</span>, the models appear to identify more fine-grained topics and the coherent bands fade.</p>
<p>We next constructed Silge plots <span class="citation" data-cites="SilgeTopicModeling2017">[@SilgeTopicModeling2017]</span>, showing the top 15 (highest-probability) terms (noun phrases) from each topic in the model. These are provided as supplemental PDFs S2-S4. Perusing these term lists, we focused on topics in each model that contained racial terms. Every fitted topic model included at least one racial topic. Importantly, in some cases these topics contained terms related to intelligence research, but in other cases they did not.</p>
<p>The gamma distributions and Silge plots suggested that, once <span class="math inline">\(k\)</span> was sufficiently large, the topic models were distinguishing between two types of race science articles. We therefore examined the prevalence of topics that used racial terms, intelligence-research terms, or both, by journal and across all 24 models. Supplemental PDFs S5-7 provide these visualizations. In these visualizations, each row of facets corresponds to a value of <span class="math inline">\(k\)</span> (excluding 5 as too noisy), and each column of facets corresponds to one topic. Topics are clustered based on whether the top 15 terms contain racial terms (“race”), terms related to intelligence research (“intelligence”), or both. Line plots show the count of articles with <span class="math inline">\(\gamma &gt; 0.50\)</span> for the given topic, by journal; thick lines are 5-year running averages and thin lines are raw counts.</p>
<p>Across all three vocabularies, for sufficiently large values of <span class="math inline">\(k\)</span> the models identify two or more different racial topics, one that appears all but exclusively in MQ and at least one that appears primarily in mainstream journals.</p>
<p>We next conducted a topic quality check of topic 24 from the medium vocabulary, <span class="math inline">\(k=40\)</span> model, which appeared to identify race science research on intelligence published in mainstream journals. A spreadsheet of all articles that had a maximum value of <span class="math inline">\(\gamma\)</span> for this topic was extracted (excluding articles published in <em>Psychological Reports</em>), and the top 121 articles (<span class="math inline">\(\gamma &gt; 0.97\)</span>) were reviewed manually by both authors. We coded each article as <em>race science discourse</em>, or not, using our definition of race science discourse as treating race science as a legitimate area of scientific reearch; this includes methodological critiques of race science and empirical tests that falsify race science hypotheses.</p>
<p>For the first round of review, both authors worked independently, dichotomously coding each article as race science discourse or not. We calculated the “false positive rate” — documents with maximum <span class="math inline">\(\gamma\)</span> in this topic that were not race science discourse — and interrater reliability using Cohen’s <span class="math inline">\(\kappa\)</span>. The consensus true positive rate was 89.3% (108/121), while the consensus false positive rate was 8.3% (10/121), with 98% agreement across the two raters (<span class="math inline">\(\kappa = 0.86)\)</span>. Coding spreadsheets are included in the supplemental materials S8-S9. For each of the 10 consensus false positive documents, their inclusion in the topic was readily explained, but in different ways for different documents. Some included text from other documents, as when an article started in the middle of a page; others discussed perceptions of race relations or racial animus; one piece in BG discussed differences in the herding behavior of two cattle breeds, referred to as “white” and “black.”</p>
<p>The 3 non-consensus documents reflected essential ambiguity in the operationalization of race science discourse. One is a table of contents from a 1980 issue of Int; arguably this document should have been excluded as irrelevant front matter, but arguably it legitimizes the research published in the issue. The second case is a paper on racial differences in emotional intelligence that was classified as race science discourse by one author, while the other author felt it was more focused on psychometrics <span class="citation" data-cites="GignacGroupDifferencesEI2010">[@GignacGroupDifferencesEI2010]</span>. And a 1990 article in MQ (<a href="https://www.unz.com/print/MankindQuarterly-1990q3-00108/" class="uri">https://www.unz.com/print/MankindQuarterly-1990q3-00108/</a>) proposed to offer an economic explanation for crime. While it has a few pages connecting race/ethnicity to both crime and poverty, it ultimately focuses on unemployment and alcohol sales, rather than race, as the key predictors of crime.</p>
<p>Based on this qualitative review, we judged that the topic model approach was sufficiently sensitive (low “false positive” rate) in identifying race science discourse. However, “false negatives” are still possible, as some documents that human readers would classify as race science discourse might have been associated with other topics.</p>
</section>
</section>
<section id="bg" class="level2">
<h2 class="anchored" data-anchor-id="bg">Supplemental analysis of <em>Behavior Genetics</em></h2>
<p>To check the finding that very few race-and-intelligence documents had been published in BG, we ran an independent search for documents with the keywords “race” and “intelligence” published in BG from 1972 to 2020 using Springer’s journal search website. This search returned 125 documents. Thirty-three were presentation abstracts from meetings of the Behavior Genetics Association; we did not examine these further. Fourteen of the remaining documents had been published since 2010 (after the scope of the primary study). Among these, one obituary and two papers celebrated the work of John Loehlin, a prominent race-and-intelligence researcher who had been Director of the American Eugenics Society from 1968-1972 <span class="citation" data-cites="JohnLoehlin19262020 WaldmanIntroductionFestschriftJohn2014 PlominGenotypeEnvironmentCorrelationEra2014">[@JohnLoehlin19262020; @WaldmanIntroductionFestschriftJohn2014; @PlominGenotypeEnvironmentCorrelationEra2014]</span>. Another was a retrospective of the work of Lindon Eaves, a geneticist who made at least one notable contribution to debates on the Scarr-Rowe hypothesis (interactions between heritability, race, and class). None of these 14 documents reported any studies of racial differences.</p>
<p>Twenty-eight documents in this sample from BG were published between 1990 and 2010. One was an obituary of Jerry Hirsch, a critic of hereditarianism in general and Jensen in particular <span class="citation" data-cites="RoubertouxJerryHirsch202008">[@RoubertouxJerryHirsch202008]</span>, and another was an obituary of David Rowe <span class="citation" data-cites="RodgersObituaryDavidChristian2003">[@RodgersObituaryDavidChristian2003]</span>. Only 2 of these 28 documents reported race differences of any kind: one examining interactions among race, sex, and heritability for adolescent BMI (Body Mass Index, used as a measure of overweight/obesity) <span class="citation" data-cites="JacobsonGeneticSharedEnvironmental1998">[@JacobsonGeneticSharedEnvironmental1998]</span>; and the other interactions among race, family history of alcoholism, and visuospatial performance <span class="citation" data-cites="BermanReducedVisuospatialPerformance1995">[@BermanReducedVisuospatialPerformance1995]</span>. Finally, Philip Vernon — one of the Pioneer-funded scientists we identified earlier — published a critical review of a book that attempted to address hereditarianism, the Flynn effect, race-and-intelligence research, and some related issues.</p>
<p>At the same time, we were unable to find any articles published in BG that acknowledged the involvement of the field with scientific racism with anything like the force of the statements that have been made by biological anthropologists <span class="citation" data-cites="FuentesAAPAStatementRace2019">[@FuentesAAPAStatementRace2019]</span> and human geneticists <span class="citation" data-cites="JacksonFacingOurHistory2023">[@JacksonFacingOurHistory2023]</span>. Notably, the ASHG report includes discussions of behavior genetics race science, and in particular is critical of the field and the organization for failing to publicly reject the race-and-intelligence claims made by Shockley and Jensen <span class="citation" data-cites="JacksonFacingOurHistory2023">[@JacksonFacingOurHistory2023]</span>. A search for “eugenics” in BG found articles that presented the issue as part of the distant past, and a search for “racism” turned up studies of racist attitudes. A statement on the Behavior Genetics Association website, dated 2021, acknowledges that “The history of our field is inextricably linked with racism, including the misuse of behavior genetic research to support violent eugenic policies,” but primarily focuses on BGA member demographics (<a href="https://www.bga.org/content.aspx?page_id=22&amp;club_id=971921&amp;module_id=567723" class="uri">https://www.bga.org/content.aspx?page_id=22&amp;club_id=971921&amp;module_id=567723</a>).</p>
</section>
<section id="limitations" class="level2">
<h2 class="anchored" data-anchor-id="limitations">Limitations</h2>
<p>A key limitation of the current study stems from the inability of text mining techniques to draw on a broader cultural context than what is represented in the corpus. Scholars of racism and US race relations have noted a shift in the way racist attitudes are understood and expressed, from overt and direct to a subtle “color-blind” racism <span class="citation" data-cites="Bonilla-SilvaRacismRacistsColorBlind2006">[@Bonilla-SilvaRacismRacistsColorBlind2006]</span>. Color-blind racism represents a change in the primary mechanisms by which white privilege is maintained, using non-racialized language in furtherance of the racial status quo both institutionally and individually, and increasingly reliant on the invisibility of socio-cultural mechanisms to preserve inequalities. Color-blind racism involves the use of racialized “codes” or “dogwhistles,” language that is superficially non-racial but carries racial implications, such as (in the US context) “violent inner city criminals” or “welfare queen” <span class="citation" data-cites="SaulDogwhistlesPoliticalManipulation2018">[@SaulDogwhistlesPoliticalManipulation2018]</span>. Alderfer notes that the racist implications of <em>The Bell Curve</em> only emerge gradually, with the opening of the book using the color-blind language of “group differences” <span class="citation" data-cites="AlderferScienceNonsciencePsychologists2003">[@AlderferScienceNonsciencePsychologists2003]</span>. These cases suggest further that color-blindness can facilitate white supremacist appropriation of non-racial research — even contrary to the researchers’ own intentions — as scientific racist readers re-interpret racial-neutral language as dogwhistles <span class="citation" data-cites="GillbornSoftlySoftlyGenetics2016 WillsAreClustersRaces2017">[@GillbornSoftlySoftlyGenetics2016; @WillsAreClustersRaces2017]</span>.</p>
<p>Techniques such as topic modeling may be able to account for discursive shifts from explicit to coded racial language, but only if the corpus contains a critical mass of documents using both sets of terms together. This would seem to require either a relatively gradual transition, the inclusion of reflective commentary — such as scholarship identifying and analyzing the transition — or both. It is unlikely that these requirements are met by the corpus used in this study. So it is plausible that the topic models used here have some rate of “false negatives,” documents in the corpus that engage in race science discourse but in a color-blind way that avoids the use of the explicit racial terms in the race-and-intelligence topic.</p>
<p>The phenomenon of color-blind racism is closely related to ambiguities that cannot be resolved even by human coders familiar with the broader cultural context. Two relevant examples are the “Flynn effect,” a secular increase in intelligence test scores noted by philosopher James Flynn; and studies of “national IQ,” exemplified by the work of Richard Lynn. The Flynn effect implies that environmental factors can create group differences in IQ that are comparable to Black-White differences, and thus directly challenges claims that the racial differences are biological. Using methods widely regarded as ad hoc, cherry-picking, and generally unreliable, Lynn and collaborators have claimed that national IQ averages are correlated with national GDP. Both the Flynn effect and “national IQ” are strongly associated with race-and-intelligence discourse in the US cultural context. But scientific journal articles on these topics may not include any racial language at all. For example, a meta-analysis of the Flynn effect does not discuss racial differences or use terms such as “White” or “Black” outside the reference list <span class="citation" data-cites="TrahanFlynnEffectMetaanalysis2014">[@TrahanFlynnEffectMetaanalysis2014]</span>. Should such articles be coded as race science discourse? We expect that even readers who accept our definitions of race science and race science discourse will reasonably disagree on how to answer this question. Topic models, of course, are not even capable of representing this essential ambiguity.</p>
</section>
</section>
<section id="references" class="level1">
<h1>References</h1>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>